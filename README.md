# Engram MCP

<p align="center">
  <strong>A local, sovereign, hybrid memory system for MCP-compatible agents</strong>
</p>

<p align="center">
  Semantic search â€¢ Lexical search â€¢ Persistent memory â€¢ Non-blocking â€¢ Secure by default
</p>

---

## ğŸ§  What is Engram MCP?

**Engram MCP** is a highâ€‘performance, openâ€‘source memory server that gives AI agents *longâ€‘term, searchable memory*.

In neuroscience, an **engram** is the physical trace of a memory in the brain.  
Engram MCP brings that concept to AI systems: durable, auditable, local memory that scales from small projects to universal personal knowledge bases.

Engram is **not** a chat log.  
It is **not** a volatile cache.  

It is a **cognitive substrate** for agents.

---

## âœ¨ Core Features

### ğŸ” Hybrid Search (State of the Art)
- **Vector similarity search** (FAISS)
- **Lexical BM25 search** (SQLite FTS5, onâ€‘disk)
- **Reciprocal Rank Fusion (RRF)** for bestâ€‘ofâ€‘bothâ€‘worlds ranking

### âš¡ Nonâ€‘Blocking Architecture
- Embeddings offloaded from the event loop
- Async SQLite via `aiosqlite`
- Long indexing jobs do **not** freeze search or control tools

### ğŸ—‚ï¸ Persistent & Incremental Indexing
- Chunkâ€‘level hashing & deduplication
- `ON CONFLICT` upserts
- Automatic reâ€‘indexing when files change

### ğŸ” Securityâ€‘First by Default
- Explicit **path whitelisting**
- Protection against path traversal & symlink escape
- Refuses to index outside configured roots

### ğŸ§© MCPâ€‘Native
- Built on the **official MCP SDK / FastMCP**
- No manual JSONâ€‘RPC parsing
- Forwardâ€‘compatible with protocol changes

### ğŸ§ª Productionâ€‘Grade
- Modular architecture
- Clear separation of concerns
- Suitable for longâ€‘running agent workloads

---

## ğŸ—ï¸ Architecture Overview

```
engram_mcp/
â”œâ”€â”€ server.py            # MCP entrypoint
â”œâ”€â”€ config.py            # Configuration & security guards
â”œâ”€â”€ indexing/
â”‚   â”œâ”€â”€ indexer.py       # File discovery & chunking
â”‚   â””â”€â”€ workers.py       # Background execution
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ encoder.py       # Embedding model logic
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ schema.sql       # Tables, FTS5, triggers
â”‚   â””â”€â”€ store.py         # Async database access
â”œâ”€â”€ search/
â”‚   â””â”€â”€ hybrid.py        # Vector + BM25 + RRF
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ paths.py
â”‚   â””â”€â”€ hashing.py
â””â”€â”€ engram_mcp.yaml.example
```

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/yourname/engram-mcp.git
cd engram-mcp
```

---

### 2ï¸âƒ£ Configure allowed paths
```bash
cp engram_mcp.yaml.example engram_mcp.yaml
```

Edit **`allowed_roots`**:

```yaml
allowed_roots:
  - /Users/you/Documents
  - /Users/you/Projects
```

> âš ï¸ Engram **will refuse** to index anything outside these paths.

---

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

All dependencies are resolved **at install time**.  
No runtime downloads. No surprises.

---

### 4ï¸âƒ£ Run the server
```bash
python server.py
```

Engram MCP is now available to MCPâ€‘compatible clients.

---

## ğŸ§  MCP Tools

### `index_project`
Indexes a directory (must be within `allowed_roots`).

```json
{
  "path": "/Users/you/Projects/my_repo"
}
```

---

### `search_memory`
Hybrid semantic + lexical search.

```json
{
  "query": "async sqlite performance issues",
  "limit": 10
}
```

---

### `delete_project`
Removes all indexed content for a project root.

---

## ğŸ”’ Security Model

Engram MCP **will refuse** to index paths that:

- Are outside `allowed_roots`
- Escape via symlinks
- Attempt traversal (`../`)

This prevents accidental indexing of:
- `/`
- `.ssh`
- System files
- Private or sensitive directories

Security is **optâ€‘in by configuration**, not implicit trust.

---

## âš™ï¸ Performance Notes

### Embeddings
- Executed off the event loop
- CPU â†’ `ProcessPoolExecutor`
- CUDA â†’ threadâ€‘safe execution (no fork hazards)

### Search
- Vector search via FAISS
- Lexical search via SQLite FTS5
- No inâ€‘memory BM25 structures

### Indexing
- Streaming file readers
- No `f.read()` on large files
- Safe for multiâ€‘GB corpora

---

## ğŸ§  Philosophy

Large Language Models are powerful â€” but **stateless**.

Engram MCP exists to give agents:
- Memory that persists
- Knowledge they can revisit
- Context they can build upon

This is not convenience infrastructure.

This is **cognition infrastructure**.

---

## ğŸ›£ï¸ Roadmap

- Binary vector quantization (32Ã— memory reduction)
- Tantivy / Lucene backend option
- Namespace isolation & multiâ€‘tenant memory
- Hotâ€‘swappable embedding models
- Crossâ€‘agent shared memory graphs

---

## ğŸ¤ Contributing

Contributions are welcome.

If you are interested in:
- Retrieval systems
- Agent architectures
- Localâ€‘first AI
- Highâ€‘performance Python

Youâ€™ll feel at home here.

---

## ğŸ“œ License

MIT License.

Build agents that remember.
